# Standard web crawlers
User-agent: *
Disallow: /admin/
Disallow: /login/
Disallow: /cart/
Disallow: /checkout/
Disallow: /search?
Allow: /

# Ensure assets used in rendering are crawlable
Allow: /assets/
Allow: /static/
Allow: /images/
Allow: /css/
Allow: /js/

# Sitemaps
Sitemap: https://successnow.ai/sitemap.xml
Sitemap: https://successnow.ai/sitemap-pages.xml
Sitemap: https://successnow.ai/sitemap-posts.xml

# AI/model training crawlers - restrict while allowing normal search bots
User-agent: GPTBot
Disallow: /

User-agent: Google-Extended
Disallow: /

User-agent: CCBot
Disallow: /

User-agent: Amazonbot
Disallow: /

User-agent: Applebot-Extended
Disallow: /
